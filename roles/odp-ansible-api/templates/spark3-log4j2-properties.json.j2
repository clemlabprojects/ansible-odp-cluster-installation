{
	"Clusters": {
		"desired_configs": {
			"type": "spark3-log4j2-properties",
			"tag": "{{ range(00000000, 99999999) | random }}",
			"properties": { {% raw %}
        "content" : "\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the License); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an AS IS BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n# Set everything to be logged to the console\nrootLogger.level = info\nrootLogger.appenderRef.stdout.ref = console\n\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n%ex\n\n# Settings to quiet third party logs that are too verbose\nlogger.jetty.name = org.sparkproject.jetty\nlogger.jetty.level = warn\nlogger.jetty2.name = org.sparkproject.jetty.util.component.AbstractLifeCycle\nlogger.jetty2.level = error\nlogger.repl1.name = org.apache.spark.repl.SparkIMain$exprTyper\nlogger.repl1.level = info\nlogger.repl2.name = org.apache.spark.repl.SparkILoop$SparkILoopInterpreter\nlogger.repl2.level = info\n\n# Set the default spark-shell log level to WARN. When running the spark-shell, the\n# log level for this class is used to overwrite the root logger's log level, so that\n# the user can have different defaults for the shell and regular Spark apps.\nlogger.repl.name = org.apache.spark.repl.Main\nlogger.repl.level = warn\n\n# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs\n# in SparkSQL with Hive support\nlogger.metastore.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler\nlogger.metastore.level = fatal\nlogger.hive_functionregistry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry\nlogger.hive_functionregistry.level = error\n\n# Parquet related logging\nlogger.parquet.name = org.apache.parquet.CorruptStatistics\nlogger.parquet.level = error\nlogger.parquet2.name = parquet.CorruptStatistics\nlogger.parquet2.level = error"
        {% endraw %}
      }
    }
  }
}
